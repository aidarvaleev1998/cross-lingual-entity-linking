{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: sapbert/train/generalized_wikidata_train.sh: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat sapbert/train/generalized_wikidata_train.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load sapbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"sapbert_xlm_roberta_base\"\n",
    "path = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)  \n",
    "model = AutoModel.from_pretrained(path).cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"sapbert_wikidata_collated\"\n",
    "path = \"experiments/sapbert_wikidata_collated/model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, local_files_only=True)  \n",
    "model = AutoModel.from_pretrained(path, local_files_only=True).cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"sapbert_wikititles\"\n",
    "path = \"experiments/sapbert_wikititles/model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(path, local_files_only=True)  \n",
    "model = AutoModel.from_pretrained(path, local_files_only=True).cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data, idx=1):\n",
    "    bs = 128\n",
    "    all_reps = []\n",
    "    for i in tqdm(np.arange(0, len(data), bs)):\n",
    "        batch = [x[idx] for x in data[i:i+bs]]\n",
    "        toks = tokenizer.batch_encode_plus(\n",
    "            batch, padding=\"max_length\", max_length=25, truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        toks_cuda = {}\n",
    "        for k,v in toks.items():\n",
    "            toks_cuda[k] = v.cuda(0)\n",
    "        output = model(**toks_cuda)\n",
    "\n",
    "    #     output = model(**toks)\n",
    "        cls_rep = output[0][:,0,:]\n",
    "\n",
    "        all_reps.append(cls_rep.cpu().detach().numpy())\n",
    "    return np.concatenate(all_reps, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/wikidata_disumbiguation.csv\", encoding=\"utf-8\") as f:\n",
    "    disambiguations = f.readlines()\n",
    "\n",
    "disambiguations = [x.split(\"entity/\")[1].strip() for x in disambiguations[1:]]\n",
    "disambiguations = set(disambiguations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_type = \"wikidata-filtered\"\n",
    "with open(\"data/wikidata-filtered-ru.tsv\", encoding=\"utf-8\") as f:\n",
    "    wikidata = f.readlines()\n",
    "wikidata = [x.strip().split(\"\\t\")[1:] for x in wikidata[1:]]\n",
    "wikidata = [x for x in wikidata if x[0] not in disambiguations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikidata_type = \"wikidata\"\n",
    "with open(\"data/wikidata.txt\", encoding=\"utf-8\") as f:\n",
    "    wikidata = f.readlines()\n",
    "wikidata = [x.strip().split(\"||\")[:2] for x in wikidata]\n",
    "wikidata = [x for x in wikidata if x[0] not in disambiguations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41674/41674 [57:18<00:00, 12.12it/s] \n"
     ]
    }
   ],
   "source": [
    "wikidata_emb = encode(wikidata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikidata\n"
     ]
    }
   ],
   "source": [
    "print(wikidata_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"experiments/{experiment}/results/{wikidata_type}.pickle\", \"wb\") as f:\n",
    "#     pickle.dump(wikidata_emb, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f\"experiments/{experiment}/results/{wikidata_type}.pickle\", \"rb\") as f:\n",
    "#     wikidata_emb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tacred 2411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tacred = []\n",
    "for file in glob.glob(\"data/tacred_2411/*/*.ann\"):\n",
    "    with open(file, encoding=\"utf-8\") as f:\n",
    "        data = f.readlines()\n",
    "\n",
    "    entities = {}\n",
    "    for line in data:\n",
    "        if \"Reference\" in line and \"Wikidata:\" in line:\n",
    "            tag, wd_id = line.split()[2:4]\n",
    "            entities[tag] = wd_id.replace(\"Wikidata:\", \"\").strip()\n",
    "\n",
    "    for line in data:\n",
    "        tag, *tmp = line.split(\"\\t\")\n",
    "        if tag[0] == \"T\" and tag in entities:\n",
    "            tacred.append((entities[tag], tmp[1].strip(), tmp[0].split()[0]))\n",
    "\n",
    "\n",
    "tacred = list(tacred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29962"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tacred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15886789933916293"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x[0] == \"NULL\" for x in tacred) / len(tacred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [00:19<00:00, 12.16it/s]\n"
     ]
    }
   ],
   "source": [
    "tacred_emb = encode(tacred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encode nerel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "# data = []\n",
    "# for file in glob.glob(\"NEREL/train/*.ann\"):\n",
    "#     with open(file, encoding=\"utf-8\") as f:\n",
    "#         tmp = f.readlines()\n",
    "#         tmp = [file + \"\\t\" + x.replace(\"\\n\", \"\") for x in tmp]\n",
    "#         data.extend(tmp)\n",
    "# nerel = [x.split(\"\\t\") for x in data if x.split(\"\\t\")[1][0] == \"T\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(nerel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nerel[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nerel_emb = encode(nerel, idx=3)\n",
    "# print(nerel_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Доминик де Вильпен\"\n",
    "# query_toks = tokenizer.batch_encode_plus(\n",
    "#     [query], padding=\"max_length\", max_length=25, truncation=True, return_tensors=\"pt\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_output = model(**query_toks)\n",
    "# query_cls_rep = query_output[0][:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_cls_rep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### top1 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5334165, 768)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikidata_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29962, 768)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tacred_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-02 15:14:15.594703\n",
      "2021-12-02 15:31:11.942504\n",
      "CPU times: user 1h 7min 10s, sys: 16.3 s, total: 1h 7min 26s\n",
      "Wall time: 16min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now())\n",
    "dim = 768\n",
    "\n",
    "index = faiss.index_factory(dim, \"IVF65536_HNSW32,Flat\")\n",
    "\n",
    "res = faiss.StandardGpuResources()\n",
    "index_ivf = faiss.extract_index_ivf(index)\n",
    "index_flat = faiss.IndexFlatL2(768)\n",
    "clustering_index = faiss.index_cpu_to_gpu(res, 0, index_flat)  #  0 – номер GPU\n",
    "index_ivf.clustering_index = clustering_index\n",
    "\n",
    "index.train(wikidata_emb)\n",
    "index.add(wikidata_emb)\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-02 15:31:12.206713\n",
      "2021-12-02 15:31:20.086462\n",
      "CPU times: user 52.8 s, sys: 360 ms, total: 53.2 s\n",
      "Wall time: 7.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.now())\n",
    "topn = 5\n",
    "index.nprobe = 16  # Проходим по топ-16 центроид для поиска top-n ближайших соседей\n",
    "D, I = index.search(tacred_emb, topn)\n",
    "I.shape\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [\n",
    "    str(tacred[i]) + \"\\tPred: \" + str((wikidata[I[i][0]][0], wikidata[I[i][0]][1]))\n",
    "    for i in range(len(I))\n",
    "]\n",
    "\n",
    "with open(f\"experiments/{experiment}/results/out-{wikidata_type}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(len(I)):\n",
    "        f.write(result[i] + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH = 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(index, null_thresh=None):\n",
    "    y_true = [tacred[i][0] for i in index]\n",
    "    y_pred = [[wikidata[pred][0] if null_thresh is None or dist < null_thresh else \"NULL\"\n",
    "               for pred, dist in zip(I[i], D[i])]\n",
    "              for i in index]\n",
    "    \n",
    "    top1 = sum(t in p[:1] for t, p in zip(y_true, y_pred)) / len(y_true)\n",
    "    top3 = sum(t in p[:3] for t, p in zip(y_true, y_pred)) / len(y_true)\n",
    "    top5 = sum(t in p[:5] for t, p in zip(y_true, y_pred)) / len(y_true)\n",
    "    null = sum(\"NULL\" in p[:1] for t, p in zip(y_true, y_pred))\n",
    "    return top1, top3, top5, null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tacred Accuracy on wikidata\n",
      "NULL Treshold 220\n",
      "Top1\tT1+Null\tTop3\tT3+Null\tTop5\tT5+Null\tNULL\tN\tGroup\n",
      "0.209\t0.277\t0.346\t0.482\t0.355\t0.529\t59\t512\tAWARD\n",
      "0.033\t0.031\t0.076\t0.071\t0.107\t0.100\t143\t1687\tCITY\n",
      "0.030\t0.028\t0.112\t0.108\t0.142\t0.133\t140\t3602\tCOUNTRY\n",
      "0.251\t0.263\t0.299\t0.317\t0.335\t0.353\t19\t167\tDISTRICT\n",
      "0.144\t0.207\t0.240\t0.334\t0.254\t0.374\t130\t575\tFACILITY\n",
      "0.347\t0.347\t0.551\t0.551\t0.551\t0.551\t0\t49\tLANGUAGE\n",
      "0.135\t0.381\t0.156\t0.493\t0.164\t0.548\t221\t653\tLAW\n",
      "0.066\t0.101\t0.125\t0.184\t0.134\t0.198\t46\t424\tLOCATION\n",
      "0.250\t0.252\t0.384\t0.386\t0.457\t0.459\t17\t560\tNATIONALITY\n",
      "0.270\t0.310\t0.392\t0.459\t0.418\t0.493\t776\t5851\tORGANIZATION\n",
      "0.197\t0.244\t0.238\t0.296\t0.249\t0.319\t2303\t7450\tPERSON\n",
      "0.494\t0.501\t0.569\t0.586\t0.571\t0.607\t29\t399\tPRODUCT\n",
      "0.279\t0.341\t0.445\t0.550\t0.500\t0.630\t696\t6883\tPROFESSION\n",
      "0.420\t0.420\t0.629\t0.643\t0.706\t0.720\t4\t143\tRELIGION\n",
      "0.092\t0.094\t0.180\t0.180\t0.221\t0.217\t26\t566\tSTATE_OR_PROVINCE\n",
      "0.239\t0.303\t0.315\t0.408\t0.348\t0.450\t69\t422\tWORK_OF_ART\n",
      "\n",
      "0.202\t0.245\t0.299\t0.364\t0.329\t0.406\t4682\t29962\tTotal (Micro)\n",
      "0.216\t0.256\t0.316\t0.378\t0.345\t0.418\t\t\tTotal (Macro)\n"
     ]
    }
   ],
   "source": [
    "# groups = set(x[2] for x in tacred)\n",
    "# groups.remove(l)\n",
    "groups = set(['AWARD', 'CITY', 'COUNTRY', 'DISTRICT','FACILITY', 'LANGUAGE', 'LAW', 'LOCATION', 'NATIONALITY', \n",
    "          'ORGANIZATION','PERSON', 'PRODUCT', 'PROFESSION', 'RELIGION', 'STATE_OR_PROVINCE', 'WORK_OF_ART'])\n",
    "\n",
    "result = f\"Tacred Accuracy on {wikidata_type}\\n\"\n",
    "result += f\"NULL Treshold {THRESH}\\n\"\n",
    "result += \"Top1\\tT1+Null\\tTop3\\tT3+Null\\tTop5\\tT5+Null\\tNULL\\tN\\tGroup\\n\"\n",
    "group_res = []\n",
    "for g in sorted(groups):\n",
    "    group_idx = [i for i, x in enumerate(tacred) if x[2] == g]\n",
    "    t1n, t3n, t5n, null = accuracy(group_idx, null_thresh=THRESH)\n",
    "    t1, t3, t5, _ = accuracy(group_idx)\n",
    "    \n",
    "    group_res.append((t1, t1n, t3, t3n, t5, t5n))\n",
    "    result += f\"{t1:.3f}\\t{t1n:.3f}\\t{t3:.3f}\\t{t3n:.3f}\\t{t5:.3f}\\t{t5n:.3f}\\t{null}\\t{len(group_idx)}\\t{g}\\n\"\n",
    "\n",
    "result += \"\\n\"\n",
    "t1n, t3n, t5n, null = accuracy(range(len(tacred)), null_thresh=THRESH)\n",
    "t1, t3, t5, _ = accuracy(range(len(tacred)))\n",
    "result += f\"{t1:.3f}\\t{t1n:.3f}\\t{t3:.3f}\\t{t3n:.3f}\\t{t5:.3f}\\t{t5n:.3f}\\t{null}\\t{len(tacred)}\\tTotal (Micro)\\n\"\n",
    "\n",
    "t1, t1n, t3, t3n, t5, t5n = [sum(x[i] for x in group_res) / len(group_res) for i in range(6)]\n",
    "result += f\"{t1:.3f}\\t{t1n:.3f}\\t{t3:.3f}\\t{t3n:.3f}\\t{t5:.3f}\\t{t5n:.3f}\\t\\t\\tTotal (Macro)\"\n",
    "print(result)\n",
    "with open(f\"experiments/{experiment}/results/accuracy-{wikidata_type}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
